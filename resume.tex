%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is a modified ONE COLUMN version of
% the following template:
% 
% Deedy - One Page Two Column Resume
% LaTeX Template
% Version 1.1 (30/4/2014)
%
% Original author:
% Debarghya Das (http://debarghyadas.com)
%
% Original repository:
% https://github.com/deedydas/Deedy-Resume
%
% IMPORTANT: THIS TEMPLATE NEEDS TO BE COMPILED WITH XeLaTeX
%
% This template uses several fonts not included with Windows/Linux by
% default. If you get compilation errors saying a font is missing, find the line
% on which the font is used and either change it to a font included with your
% operating system or comment the line out to use the default font.
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% TODO:
% 1. Integrate biber/bibtex for article citation under publications.
% 2. Figure out a smoother way for the document to flow onto the next page.
% 3. Add styling information for a "Projects/Hacks" section.
% 4. Add location/address information
% 5. Merge OpenFont and MacFonts as a single sty with options.
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% CHANGELOG:https://www.overleaf.com/project/64626850e3f021a109e50d5b
% v1.1:
% 1. Fixed several compilation bugs with \renewcommand
% 2. Got Open-source fonts (Windows/Linux support)
% 3. Added Last Updated
% 4. Move Title styling into .sty
% 5. Commented .sty file.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Known Issues:
% 1. Overflows onto second page if any column's contents are more than the
% vertical limit
% 2. Hacky space on the first bullet point on the second column.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[]{deedy-resume-openfont}


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%     LAST UPDATED DATE
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\lastupdated

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%     TITLE NAME
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\namesection{Pranesh}{Mukhopadhyay}{
% { \urlstyle{same}\url{http://example.com} \\
\href{mailto:praneshmukherjee7@gmail.com}{praneshmukherjee7@gmail.com} | 96747-70912
}

% \href{http://linkedin.com/in/12346}{http://linkedin.com/in/praneshmukhopadhyay}

\href{https://github.com/Mukhopadhyay}{\faIcon[solid]{github} github.com/Mukhopadhyay} \; \href{https://www.linkedin.com/in/praneshmukhopadhyay/}{\faIcon[solid]{linkedin} linkedin.com/in/praneshmukhopadhyay} \; \href{https://www.kaggle.com/praneshmukhopadhyay}{\faIcon[solid]{kaggle} kaggle.com/praneshmukhopadhyay}


% \begin{center}
% \huge\color{subheadings}\custombold{LIFELONG LEARNER}
% \end{center}

\section{Experience}

\runsubsection{Boxwish Media LLP. / Spiritzone}
\descript{| Consultant - Data Engineering }
\location{Dec 2021 – Present | Navi Mumbai}
\vspace{\topsep} % Hacky fix for awkward extra vertical space

\project{Order Assignment System}
\begin{tightemize}
\item Real time order assignment system made using \keyword{Python}, \keyword{FastAPI} and hosted and container orchestration handled using \keyword{Docker compose}, supporting Webhook listener \& dynamic trip creation.
\item Intelligent algorithm used to dynamically perform order batching based on delivery partner availability and order volumes. Maintaining a fair and unbiased delivery agent ranking system.
\item Added support for centralized logging using MongoDB and end to end unit testing using Pytest \& Flake8
\end{tightemize}

\project{Product Search API}
\begin{tightemize}
\item An incrementally trainable search API, which can index products even with their attributes developed using \keyword{Python} \& \keyword{Scikit-Learn} using Bag of Characters model
\item Hosted using \keyword{gunicorn} for maximizing concurrent requests
\item 80\%+ Unit test coverage using \& Passed swarm test conducted using Locust
\end{tightemize}

\project{Order ETA Calculation API}
\begin{tightemize}
\item A fast, interpretable stateless microservice for providing real time order delivery time estimates.
\item Built using \keyword{Python}, \keyword{FastAPI} \& \keyword{TensorFlow} and hosted using Docker compose for easy container orchestration.
\item Maintaining model lifecycles using \keyword{MLOps} and testing the service using \keyword{Pytest} and \keyword{Locust}
\end{tightemize}

\sectionsep

\runsubsection{Quosphere Infosolutions Pvt. Ltd.}
\descript{| Junior Data Scientist }
\location{Jul 2020 – Dec 2021 | Navi Mumbai}
\vspace{\topsep}

\location{Spiritzone Product Recommender System}

\textbullet{} \keyword{Python} \textbullet{} \keyword{Flask} \textbullet{} \keyword{Collaborative Filtering} \textbullet{} \keyword{Content based recommender system} 

\begin{tightemize}
\item A hybrid recommender system trained using user's product browsing patterns and feedback path drawn from customer engagement platforms where the models are incrementally trained using the customer interaction data.
\item Highly scalable and easily maintainable stateless microservices developed using Python and Flask. Capable of handling 30+ requests per second asynchronously.
\item End to end unit \& integration tested using python's built-in unit test library
\end{tightemize}

\location{Market Basket Analysis}

\keyword{Python} \textbullet{} \keyword{FastAPI} \textbullet{} \keyword{Apriori Algorithm} \textbullet{} \keyword{Docker compose} \textbullet{} \keyword{FP-Growth Algorithm}

\begin{tightemize}
\item Developed using the \keyword{Apriori} and \keyword{FP-Growth} algorithm for efficient, scalable and maintainable stateless microservice.
\item Used FastAPI and Docker to make the deployment process easier alongside a complete build pipeline, capable of training the the models on a daily basis.
\item Unit tests with 90\%+ code coverage \& successfully handled load testing with 30+ concurrent requests per second (conducted using Locust).
\end{tightemize}

\location{Clickstream Data Analytics Pipeline}

\keyword{Azure Data Explorer} \textbullet{} \keyword{Python} \textbullet{} \keyword{Grafana}

\begin{tightemize}
\item A data pipeline using azure's python SDK and Azure Data Explorer to move huge volume of data incrementally.
\item Scheduled reports that gets sent out everytime data ingestion process has been finished.
\item Dynamically controlling frequency of ingestion without losing any data.
\end{tightemize}

\sectionsep

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     RESEARCH
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Projects}
\runsubsection{\href{https://monolg.readthedocs.io/en/latest/}{Monolg}}
\descript{| An easy to use centralized Mongo db logging library}
% \location{Jan 2014 – Present | Ithaca, NY}

A Simple easy to use centralized logging library for Python using MongoDB. Deployed at Python Packaging Index aka. PyPI at \href{https://pypi.org/project/monolg/}{pypi.org/project/monolg}. The library was written so that any Python developer who uses the default logging library can get started with Monolg as easily. With complete documentation and user guide hosted in Read the docs at \href{https://monolg.readthedocs.io/en/latest/}{\keyword{monolg.readthedocs.io}}.

\href{https://github.com/Mukhopadhyay/monolg}{\faIcon[solid]{github} github.com/Mukhopadhyay/monolg}

\sectionsep

\runsubsection{YouTube Subtitle Dataset}
\descript{| The most versatile YouTube transcription dataset}
\location{Mar 2012 – May 2013 | Ithaca, NY}

Dataset containing 2500+ unique popular YouTube video subtitle, with manually annotated video category, that can be used as the dependent variable. Alongside the video categories we have various different video related attributes such as duration, channel name, subscriber count etc.

\href{https://www.kaggle.com/datasets/praneshmukhopadhyay/youtubers-saying-things}{\faIcon[solid]{kaggle} \keyword{kaggle.com/datasets/praneshmukhopadhyay/youtubers-saying-things}}

\sectionsep

\section{Education}
\runsubsection{St. Xavier's College}
\descript{| M.Sc in Computer Science}
\location{Aug 2020 | Kolkata, WB \textbullet{} Cum. GPA: N/A}
\location{Curriculum}

Artificial Intelligence \textbullet{} Data Structures \textbullet{} Algorithms \textbullet{} Data Warehousing \textbullet{} Compiler Desiging \textbullet{} Database Management System
\sectionsep

\runsubsection{Universitry of Calcutta}
\descript{| B.Sc in Computer Science}
\location{June 2018 | Kolkata, WB}
Dean's List (All Semesters) \textbullet{}
Cum. GPA: 3.92 / 4.0 \textbullet{}
Major GPA: 3.94 / 4.0

\location{Curriculum}

Data Structures \textbullet{} Algorithms \textbullet{} Database Management System \textbullet{} Automata

\sectionsep

\section{Skills}
\begin{minipage}[t]{.6\textwidth}
\subsection{Programming}
Python \textbullet{}   C++ \textbullet{} JavaScript
\subsection{Libraries \& frameworks}
TensorFlow \textbullet{} PyTorch \textbullet{} Pandas \textbullet{} Numpy \textbullet{} Scipy \textbullet{} FastAPI
\subsection{Databases}
MSSQL \textbullet{} PostgreSQL \textbullet{} MongoDB \textbullet{} MySQL
\subsection{DevOps and other tools}
Docker \textbullet{} Kubernetes \textbullet{} Github Actions \textbullet{} Azure Pipelines \textbullet{} Grafana
\sectionsep
\end{minipage}

\sectionsep

% \begin{minipage}[t]{.35\textwidth}
\section{Certificates}
\keyword{Machine Learning by Stanford University}\\
\href{https://www.coursera.org/account/accomplishments/verify/636WHFRBMH5V}{\faCertificate\; Coursera} \textbullet{} Certificate ID: \textbf{636WHFRBMH5V}
\vspace{\topsep}\\
\keyword{Data Science Math Skills by Duke University}\\
\href{https://www.coursera.org/account/accomplishments/verify/AFQSU5CAT4HD}{\faCertificate\; Coursera} \textbullet{} Certificate ID: \textbf{AFQSU5CAT4HD}
\vspace{\topsep}\\
\keyword{Introduction to TensorFlow for Artificial Intelligence by DeepLearning.AI}\\
\href{https://www.coursera.org/account/accomplishments/verify/E3XDATA99F3Y}{\faCertificate\; Coursera} \textbullet{} Certificate ID: \textbf{E3XDATA99F3Y}


% \location{Reading fluency:} Chinese, Japanese\\
% \end{minipage}

\end{document}  \documentclass[]{article}